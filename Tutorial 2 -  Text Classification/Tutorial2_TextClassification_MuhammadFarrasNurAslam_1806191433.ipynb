{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kTDLxnqTgk-"
   },
   "source": [
    "<center><b>CSIE604284 • Analitika Media Sosial</b></center>\n",
    "<center><b>Fakultas Ilmu Komputer, Universitas Indonesia</b></center>\n",
    "<center><b>Tutorial 2 - Text Classification</b></center>\n",
    "<center><i>Deadline</i> Pengumpulan: Jumat, 04 Juni 2021, pukul 22.00</center>\n",
    "\n",
    "<b>Instruksi Pengerjaan</b>:\n",
    "* Tugas ini adalah tugas individu. \n",
    "* Anda diberikan berkas Tutorial2_TextClassification.ipynb dan kumpulan data pada folder dataset.\n",
    "* Tuliskan jawaban Anda pada berkas ini dan kumpulkan melalui SCeLE dengan format penamaan Tutorial2_Nama_NPM.ipynb sebelum tanggal 04 Juni 2021 pukul 22:00. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gbsoE1RTglA"
   },
   "source": [
    "<b>Tuliskan nama dan NPM Anda di sini</b><br>\n",
    "Nama: Muhammad Farras Nur Aslam\n",
    "<br>\n",
    "NPM: 1806191433"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "GzY2TEr9G-Zg"
   },
   "source": [
    "# A. Klasifikasi gender dari profil user Twitter\n",
    "\n",
    "Tutorial ini menggunakan <i>dataset</i> dari <a href='https://www.kaggle.com/efeergun96/classification-by-tweets-nlp'>Kaggle</a> yang telah dimodifikasi untuk mengklasifikasikan <i>gender</i> pengguna Twitter. <i>Dataset</i> ini memuat informasi pengguna Twitter dan juga sampel <i>tweet</i>. Tabel 1 merangkum informasi atribut pada <i>dataset</i> yang digunakan pada tutorial ini (<i>data_gender.csv</i>). \n",
    "\n",
    "Tabel 1. Informasi Atribut pada <i>Dataset data_gender.csv</i>\n",
    "\n",
    "|Nama Atribut|Jenis Data|Keterangan| \n",
    "|------|------|------|\n",
    "|<i>gender</i>|kategorikal|gender penggunan Twitter, akan digunakan sebagai label|\n",
    "|<i>fav_number</i>|numerik|jumlah tweet yang difavoritkan oleh pengguna|\n",
    "|<i>link_color</i>|kategorikal|warna link pada profil pengguna, dituliskan dalam hex code|\n",
    "|<i>retweet_count</i>|numerik|jumlah tweet yang di-retweet oleh pengguna|\n",
    "|<i>sidebar_color</i>|kategorikal|warna sidebar pada profil pengguna, dituliskan dalam hex code|\n",
    "|<i>tweet_count</i>|numerik|jumlah tweet yang ditulis oleh pengguna|\n",
    "|<i>user_timezone</i>|kategorikal|jenis zona waktu pengguna|\n",
    "\n",
    "Langkah-langkah untuk mengklasifikasikan <i>gender</i> dari <i>dataset</i> tersebut adalah sebagai berikut:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "E9lmh2ccTglB"
   },
   "source": [
    "<b>1. Membaca data</b><br>\n",
    "Library pandas digunakan untuk membaca <i>dataset</i>. Tipe data yang terbentuk setelah membaca berkas csv menggunakan fungsi $read\\_csv$ dari pandas adalah <i>dataframe</i>. Untuk mengetahui dimensi dari <i>dataframe</i> yang terbentuk, dapat digunakan properti $shape$. Sementara itu, $data.head()$ digunakan untuk menampilkan sampel data (5 teratas). \n",
    "\n",
    "<b>#Code 1</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T15:30:42.636254Z",
     "start_time": "2021-05-31T15:30:40.387053Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "executionInfo": {
     "elapsed": 1425,
     "status": "error",
     "timestamp": 1587999599410,
     "user": {
      "displayName": "Hadi Syah Putra",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjFq8cRfVCtoWipwZWKSOI_noyvowyse5zRadkS2g=s64",
      "userId": "02288041668049318883"
     },
     "user_tz": -480
    },
    "id": "QQ5cqv6zG-Zh",
    "outputId": "fcf8c088-89a4-4fc6-afe6-c48d5b54889f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6323, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>fav_number</th>\n",
       "      <th>link_color</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>sidebar_color</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>08C2C2</td>\n",
       "      <td>0</td>\n",
       "      <td>FFFFFF</td>\n",
       "      <td>110964</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>37318</td>\n",
       "      <td>3B94D9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31462</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>3901</td>\n",
       "      <td>F5ABB5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20036</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1825</td>\n",
       "      <td>9266CC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>482</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>female</td>\n",
       "      <td>3115</td>\n",
       "      <td>9266CC</td>\n",
       "      <td>0</td>\n",
       "      <td>FFFFFF</td>\n",
       "      <td>26085</td>\n",
       "      <td>Amsterdam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  fav_number link_color  retweet_count sidebar_color  tweet_count  \\\n",
       "0    male           0     08C2C2              0        FFFFFF       110964   \n",
       "1  female       37318     3B94D9              0             0        31462   \n",
       "2  female        3901     F5ABB5              0             0        20036   \n",
       "3  female        1825     9266CC              0             0          482   \n",
       "4  female        3115     9266CC              0        FFFFFF        26085   \n",
       "\n",
       "                user_timezone  \n",
       "0                     Chennai  \n",
       "1                           -  \n",
       "2  Central Time (US & Canada)  \n",
       "3                           -  \n",
       "4                   Amsterdam  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# membaca data menggunakan pandas\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('dataset/gender-data.csv', delimiter=',')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T15:14:09.429391Z",
     "start_time": "2020-04-27T15:14:09.425721Z"
    },
    "editable": false,
    "id": "2jmgoDhVTglC"
   },
   "source": [
    "<b>2. Fungsi $describe()$</b><br>\n",
    "Fungsi $describe()$ digunakan untuk menampilkan gambaran statistik singkat dari keseluruhan data atau kolom/fitur tertentu dari data.\n",
    "\n",
    "<b>#Code 2</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T03:41:28.414021Z",
     "start_time": "2020-05-14T03:41:28.318438Z"
    },
    "id": "Fau-87StG-Zm"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fav_number</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>tweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>6323.000000</td>\n",
       "      <td>6323.000000</td>\n",
       "      <td>6.323000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>7213.308082</td>\n",
       "      <td>0.099004</td>\n",
       "      <td>3.454298e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>15519.930249</td>\n",
       "      <td>2.148255</td>\n",
       "      <td>7.721278e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>329.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.245000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1951.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333100e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>7149.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.736200e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>341621.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>2.680199e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fav_number  retweet_count   tweet_count\n",
       "count    6323.000000    6323.000000  6.323000e+03\n",
       "mean     7213.308082       0.099004  3.454298e+04\n",
       "std     15519.930249       2.148255  7.721278e+04\n",
       "min         0.000000       0.000000  1.000000e+00\n",
       "25%       329.000000       0.000000  4.245000e+03\n",
       "50%      1951.000000       0.000000  1.333100e+04\n",
       "75%      7149.000000       0.000000  3.736200e+04\n",
       "max    341621.000000     153.000000  2.680199e+06"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "3twyGJ3ATglD"
   },
   "source": [
    "Fungsi $describe()$ akan menampilkan statistik standar (<i>mean</i>, <i>std</i>, <i>min</i>, <i>max</i>) untuk kolom/atribut bertipe kuantitatif (numerik), sedangkan untuk kolom bertipe kualitatif  (kategorikal) maka informasi yang akan ditampilkan berupa:\n",
    "* count: Jumlah <i>filled in</i>/ row yang terisi\n",
    "* unique: Berapa banyak nilai unik/level\n",
    "* top: Nama item yang paling banyak muncul dalam data\n",
    "* Freq: Seberapa sering top item umum muncul dalam data\n",
    "\n",
    "contoh:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T15:30:45.861147Z",
     "start_time": "2021-05-31T15:30:45.853917Z"
    },
    "id": "ncoKhFaZG-Zp",
    "outputId": "6bf2eb0b-681f-4119-bf87-1569355ad7ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2702\n",
       "FFFFFF    2662\n",
       "181A1E     236\n",
       "65B0DA     155\n",
       "5ED4DC     143\n",
       "A8C7F7     142\n",
       "BDDCAD      83\n",
       "CC3366      78\n",
       "DFDFDF      53\n",
       "DBE9ED      51\n",
       "F0A830      14\n",
       "80808        4\n",
       "Name: sidebar_color, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sidebar_color'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "uQNQpopoTglE"
   },
   "source": [
    "<b>3. Transformasi data kategorikal ke numerik</b><br>\n",
    "Atribut kategorikal perlu ditransformasi ke dalam bentuk numerik untuk bisa digunakan sebagai fitur dalam klasifikasi. Proses <i>encoding</i> dari data kategorikal ke dalam data numerik dapat dilakukan dengan properti <i>cat.codes</i>.\n",
    "\n",
    "<b>#Code 3a</b><br>\n",
    "Menampilkan tipe data sebelum transformasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T15:30:48.450151Z",
     "start_time": "2021-05-31T15:30:48.446538Z"
    },
    "id": "XiO0X_bgG-Zt",
    "outputId": "f1267e29-2c85-4f13-c37f-59f6f0920f71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Data Type before transformation \n",
      "gender           object\n",
      "fav_number        int64\n",
      "link_color       object\n",
      "retweet_count     int64\n",
      "sidebar_color    object\n",
      "tweet_count       int64\n",
      "user_timezone    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# tipe data column sebelum transformasi\n",
    "\n",
    "print(\"Column Data Type before transformation \\n\" + str(data.dtypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "d7uK9nQnTglF"
   },
   "source": [
    "<b>#Code 3b</b><br>\n",
    "Mengubah semua kolom dengan tipe “object” ke dalam bentuk “category”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T15:30:50.877151Z",
     "start_time": "2021-05-31T15:30:50.655722Z"
    },
    "id": "uMStExI7G-Zw",
    "outputId": "419e222c-ed54-4b02-b0a1-751c0aea69be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Data Type After Transformation\n",
      "gender           category\n",
      "fav_number          int64\n",
      "link_color       category\n",
      "retweet_count       int64\n",
      "sidebar_color    category\n",
      "tweet_count         int64\n",
      "user_timezone    category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "data[data.select_dtypes(['object']).columns] = data.select_dtypes(\n",
    "    ['object']).apply(lambda x: x.astype('category'))\n",
    "\n",
    "print(\"Column Data Type After Transformation\\n\" + str(data.dtypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "BQUmC4iRTglF"
   },
   "source": [
    "<b>#Code 3c</b><br>\n",
    "Melakukan <i>encoding data</i> kategorikal ke dalam tipe data numerik dengan cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T15:30:52.925809Z",
     "start_time": "2021-05-31T15:30:52.765924Z"
    },
    "id": "A9ltLLeIG-Zz",
    "outputId": "40f4173a-5856-4b0c-d3d0-001fc1f5f227",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Data Type After Transformation\n",
      "gender            int8\n",
      "fav_number       int64\n",
      "link_color       int16\n",
      "retweet_count    int64\n",
      "sidebar_color     int8\n",
      "tweet_count      int64\n",
      "user_timezone    int16\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>fav_number</th>\n",
       "      <th>link_color</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>sidebar_color</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>110964</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37318</td>\n",
       "      <td>536</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3901</td>\n",
       "      <td>1495</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20036</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1825</td>\n",
       "      <td>972</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>482</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3115</td>\n",
       "      <td>972</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>26085</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  fav_number  link_color  retweet_count  sidebar_color  tweet_count  \\\n",
       "0       1           0         130              0             11       110964   \n",
       "1       0       37318         536              0              0        31462   \n",
       "2       0        3901        1495              0              0        20036   \n",
       "3       0        1825         972              0              0          482   \n",
       "4       0        3115         972              0             11        26085   \n",
       "\n",
       "   user_timezone  \n",
       "0             40  \n",
       "1              0  \n",
       "2             39  \n",
       "3              0  \n",
       "4             11  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.select_dtypes(['category']).columns] = data.select_dtypes(\n",
    "    ['category']).apply(lambda x: x.cat.codes)\n",
    "\n",
    "print(\"Column Data Type After Transformation\\n\" + str(data.dtypes))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "H2aXC1k6TglG"
   },
   "source": [
    "<b>4. Mendefinisikan fitur dan label</b><br>\n",
    "Pada tutorial ini, dari 6 fitur  kita hanya menggunakan 3 fitur yang meliputi $link\\_color$, $sidebar\\_color$, dan $tweet\\_count$ dalam melakukan klasifikasi <i>gender</i>. Kolom <i>gender</i> digunakan sebagai label.\n",
    "\n",
    "<b>#Code 4</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T15:30:59.564925Z",
     "start_time": "2021-05-31T15:30:59.441777Z"
    },
    "id": "W4gxdb8-G-Z2"
   },
   "outputs": [],
   "source": [
    "# mendefinisikan fitur dan label\n",
    "\n",
    "feat_column = ['link_color', 'sidebar_color', 'tweet_count']\n",
    "feat = data[feat_column]\n",
    "label = data['gender']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "SeeC9auATglH"
   },
   "source": [
    "<b>5. Pembagian Data, Training dan Testing</b><br>\n",
    "Pada percobaan ini, dilakukan pembagian proporsi 90:10 dimana 90% dibagi menjadi data training dan 10% menjadi data testing. Multinomial Naïve Bayes digunakan untuk membentuk model yang mempelajari data training. Selanjutnya, model yang dibangun digunakan untuk memprediksi data testing yang tidak berlabel.\n",
    "\n",
    "<b>#Code 5a</b><br>\n",
    "Melakukan <i>import model selection</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T15:31:09.791464Z",
     "start_time": "2021-05-31T15:31:03.124215Z"
    },
    "id": "1YCb6HRXG-Z6"
   },
   "outputs": [],
   "source": [
    "# import model selection\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "hlR5L06CTglI"
   },
   "source": [
    "<b>#Code 5b</b><br>\n",
    "Pembagian data dengan proporsi 90:10 untuk <i>training</i> dan <i>testing</i> model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T15:31:15.696026Z",
     "start_time": "2021-05-31T15:31:15.680754Z"
    },
    "id": "5Di9nz3eG-Z9",
    "outputId": "1abf3c51-7c52-414e-b5dc-63885957956a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5690, 3)\n",
      "(633, 3)\n"
     ]
    }
   ],
   "source": [
    "# pembagian data dengan proporsi 90:10\n",
    "\n",
    "train_feat, test_feat, train_labels, test_labels = train_test_split(\n",
    "    feat, label, test_size=0.1, random_state=150)\n",
    "\n",
    "print(train_feat.shape)\n",
    "print(test_feat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "v3MYdjY8TglI"
   },
   "source": [
    "<b>#Code 5c</b><br>\n",
    "<i>Training</i> dan <i>testing</i> model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T15:31:18.397500Z",
     "start_time": "2021-05-31T15:31:17.989207Z"
    },
    "id": "HKcUmCMAG-aA"
   },
   "outputs": [],
   "source": [
    "# inisiasi jenis classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "NB = MultinomialNB()\n",
    "\n",
    "# training classifier\n",
    "classifier_model = NB.fit(train_feat, train_labels)\n",
    "\n",
    "# prediksi data testing\n",
    "pred = classifier_model.predict(test_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "ETj984ZnTglJ"
   },
   "source": [
    "<b>6. Evaluasi</b><br>\n",
    "Secara umum, evaluasi pada klasifikasi diukur dengan menggunakan akurasi.\n",
    "Akurasi dihitung berdasarkan jumlah data yang diprediksi benar dibagi dengan total\n",
    "data yang diuji secara keseluruhan. Namun ada pula beberapa metrik evaluasi yang\n",
    "lain, misalnya <i>precision</i> dan <i>recall</i>.\n",
    "\n",
    "<b>#Code 6</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T15:31:20.208399Z",
     "start_time": "2021-05-31T15:31:20.047577Z"
    },
    "id": "SsDNc0VdG-aC",
    "outputId": "f9a0b0f0-ebf0-4a14-93e4-7b53e23b804d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi =  0.5497630331753555\n",
      "Precision =  0.4745098039215686\n",
      "Recall =  0.44485294117647056\n",
      "F1 =  0.45920303605313095\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"Akurasi = \", accuracy_score(test_labels, pred))\n",
    "print(\"Precision = \", precision_score(test_labels, pred))\n",
    "print(\"Recall = \", recall_score(test_labels, pred))\n",
    "print(\"F1 = \",f1_score(test_labels, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fix8_WzTglJ"
   },
   "source": [
    "<b>7. Visualisasi Confusion Matrix</b><br>\n",
    "Visualisasi digunakan untuk memudahkan pembacaan <i>confusion matrix</i>. <i>Source code</i> visualisasi <i>confusion matrix</i> dapat didapatkan dari halaman resmi <a href='https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html'>scikit-learn</a>.\n",
    "\n",
    "<b><font color='red'>Tugas Tutorial A</font></b>\n",
    "1. Buatlah visualisasi <i>confusion matrix</i> yang tidak dinormalisasi dari hasil prediksi pada data testing. Buatlah interpretasi dari <i>confusion matrix</i> tersebut. \n",
    "2. Jelaskan perbedaan Decision Tree dan Random Forest. Lalu, lakukan percobaan klasifikasi data <i>gender</i> dengan model:\n",
    "    * Decision Tree jika NPM Anda diakhiri angka ganjil \n",
    "    * Random Forest jika NPM Anda diakhiri angka genap\n",
    "    \n",
    "  Lakukan evaluasi dengan parameter akurasi, <i>precision</i>, <i>recall</i>, dan F1-score. Bandingkan hasil evaluasi tersebut terhadap model Multinomial Naive Bayes yang kita gunakan sebelumnya. \n",
    "    \n",
    "3. [BONUS] Buatlah kombinasi dari 6 fitur pada data <i>gender</i> tersebut. Kombinasi fitur manakah yang paling baik berdasarkan akurasi dan model yang Anda gunakan pada soal no 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nomor 1. Visualisasi confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\asus\\anaconda3\\lib\\site-packages (21.1.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\asus\\anaconda3\\lib\\site-packages (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from scikit-learn) (1.16.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from scikit-learn) (0.13.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2164    0\n",
      "4865    1\n",
      "2312    1\n",
      "4148    0\n",
      "5130    0\n",
      "       ..\n",
      "4992    0\n",
      "261     1\n",
      "2498    1\n",
      "1184    1\n",
      "2005    1\n",
      "Name: gender, Length: 633, dtype: int8\n",
      "Confusion matrix, without normalization\n",
      "[[227 134]\n",
      " [151 121]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVQAAAEWCAYAAAA5Am/SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3debxd0/3/8df7ZhAkEgRfc8xTfkhMKWpuUL5CW4qYlZpSLdqq0BpqKKpmRfmiZjU0VRUzNQQxBBFjE0RMoSKIkOTz+2OvGyc35957brLPPfvcvJ957EfOWXvttdc++9zPWXvtvddWRGBmZnOvodYVMDPrKBxQzcxy4oBqZpYTB1Qzs5w4oJqZ5cQB1cwsJw6oFZI0v6R/SJok6Za5KGewpHvyrFutSPqupFeLsj5JfSSFpM7tVad6IWmcpG3S6+Mk/aUK6/izpBPyLreeqKNdhyppT+AoYHVgMvA8cGpEPDqX5e4NDAE2johpc13RgpMUwCoR8Uat69IcSeOAn0TEfel9H2As0CXvfSTpKmB8RByfZ7ntpelnlUN5+6XyNs2jvI6iQ7VQJR0FnAucBiwBLAdcDAzKofjlgdfmhWBaCbcCq8efbR2LiA4xAT2Bz4FdW8gzH1nAnZCmc4H50rwtgPHA0cCHwHvA/mneScDXwDdpHQcCJwLXlpTdBwigc3q/H/AfslbyWGBwSfqjJcttDDwNTEr/b1wy7yHgFOCxVM49QO9mtq2x/r8qqf/OwPeB14BPgONK8m8IPAF8mvJeCHRN8x5J2/JF2t4fl5T/a+B94K+NaWmZldI6+qf3SwETgS0q2HdXA0en10undR+W3q+cylWT9f0VmAFMSXX8Vck+2Bd4O61/aIX7f5b9ktIirf/gtO+/Tuv6RzPbEcAhwOvAf4GL+PYosAE4Hngr7Z9rgJ5NvjsHpno/UpK2P/BOKu8QYAPghbTfLixZ90rAA8DHabuvA3qVzB8HbJNen0j67qb9/nnJNA04Mc07FniT7Lv3MrBLSl8D+AqYnpb5NKVfBfy+ZJ0HAW+k/TcMWKqSz6qep5pXILcNge3Sl6FzC3lOBkYAiwOLAY8Dp6R5W6TlTwa6kAWiL4GFm34Jm3nf+AfQGVgQ+AxYLc1bElgrvd6P9IcLLJK+THun5fZI7xdN8x9KX+hVgfnT+zOa2bbG+v821f8g4CPgeqAHsFb6I1gx5V8PGJDW2wcYA/y8yRd+5TLl/4EsMM1PSYAr+QMaAywADAfOrnDfHUAKUsCeaZtvKpn395I6lK5vHClINNkHl6f6rQNMBdaoYP/P3C/lPgOaBItmtiOAO4FeZEdHHwHblWzHG8CKQHfgNuCvTep9Ddl3Z/6StD8D3YCBaf/dkeq/NFlg3jyVsTLwvbRvFiMLyueW+6xo8t0tybNuqnO/9H5Xsh/GBrIf1S+AJVv4vGZ+RsBWZIG9f6rTBcAjlXxW9Tx1pEP+RYGJ0fIh+WDg5Ij4MCI+Imt57l0y/5s0/5uIuIvs13e1OazPDKCvpPkj4r2IGF0mzw7A6xHx14iYFhE3AK8A/1uS5/8i4rWImALcTPalb843ZP3F3wA3Ar2B8yJiclr/aGBtgIh4JiJGpPWOAy4FNq9gm34XEVNTfWYREZeTtTieJPsRGdpKeY0eBr4rqQHYDDgT2CTN2zzNb4uTImJKRIwCRpEFVmh9/+fhjIj4NCLeBh7k2/01GDgnIv4TEZ8DvwF2b3J4f2JEfNHksz0lIr6KiHvIAtoNqf7vAv8G+gFExBsRcW/aNx8B59D6/pxJ0mJkwXpIRDyXyrwlIiZExIyIuIls325YYZGDgSsj4tmImJq29zupn7tRc59V3epIAfVjoHcr/U9LkR1yNXorpc0so0lA/pKsNdEmEfEF2S/6IcB7kv4pafUK6tNYp6VL3r/fhvp8HBHT0+vGP8oPSuZPaVxe0qqS7pT0vqTPyPqde7dQNsBHEfFVK3kuB/oCF6Q/pFZFxJtkP17rAt8la7lMkLQacxZQm/vMWtv/eWjLujuT9fU3eqdMeU33X3P7c3FJN0p6N+3Pa2l9f5KW7QL8Dbg+Im4sSd9H0vOSPpX0Kdl+rahMmmxv+hH5mDn/bteFjhRQnyA7JNq5hTwTyE4uNVoupc2JL8gObRv9T+nMiBgeEd8ja6m9QhZoWqtPY53encM6tcUlZPVaJSIWAo4j66dsSYuXhEjqTtYveQVwoqRF2lCfh4EfkfXjvpve7wMsTHalRpvrU0ZL+3+W/Slplv05B+uqZN3TmDVAzs06Tk/Lr5325160vj8bXUDWTzrzCgZJy5N9Z48g64LqBbxUUmZrdZ1leyUtSHYU2R7f7ZrpMAE1IiaR9R9eJGlnSQtI6iJpe0lnpmw3AMdLWkxS75T/2jlc5fPAZpKWk9ST7JAGAElLSNopfYmmkrW+ppcp4y5gVUl7Suos6cfAmmQttGrrQdbP+3lqPR/aZP4HZP19bXEe8ExE/AT4J1n/HwCSTpT0UAvLPkz2x/tIev8Q2WVqj5a0uptqax1b2v+jgLUkrSupG1k/49ysq9y6fyFphfTDcxpZP3FeV430IJ0gkrQ08MtKFpL0U7KjgD0jYkbJrAXJguZHKd/+ZC3URh8Ay0jq2kzR1wP7p89zPrLtfTJ1L3VYHSagAkTEOWTXoB5P9kV4h+yP9I6U5ffASLKzpC8Cz6a0OVnXvcBNqaxnmDUINpBdLTCB7Azn5sBhZcr4GNgx5f2Y7Ez1jhExcU7q1EbHkJ0AmkzWErmpyfwTgavT4d5urRUmaRDZicFDUtJRQH9Jg9P7ZcmuVmjOw2RBoTGgPkrWYnyk2SWyVtnxqY7HtFZHWtj/EfEa2Umr+8j6Cptet3wFsGZa1x203ZVkVyY8QnbVx1dkPxh5OYnsBNAksh+z2ypcbg+yH4oJkj5P03ER8TLwR7Ijvw+A/8es++8Bsj759yXN9n2NiPuBE4Bbya4iWQnYfU42rJ50uAv7rZgkPQ9snX5EzDokB1Qzs5x0qEN+M7NackA1M8uJA6qZWU7m6UEY1Hn+UNceta6GtcFaqy5b6ypYG7z7zlt88vHESq+HLavTQstHTJvtxryyYspHwyNiu7lZ39yYtwNq1x7Mt1qrVwRZgQy79+xaV8HaYKdtNmk9Uyti2pSK/06/ev6iSu/kqop5OqCaWT0QqD56Jx1QzazYBDR0qnUtKuKAambFp7nqhm03DqhmVnA+5Dczy49bqGZmORBuoZqZ5UNuoZqZ5cZn+c3M8uCTUmZm+RB1c8hfH2HfzOZtaqhsaq0YaVlJD0oaI2m0pCNT+lmSXpH0gqTbJfUqWeY3kt6Q9KqkbVsq3wHVzApOuQVUsgcjHh0RawADgMMlrQncC/SNiLWB10jPiEvzdgfWInvEz8WSmu3QdUA1s2IT0KlTZVMrIuK9iHg2vZ4MjAGWjoh7Sh6YOAJYJr0eBNwYEVMjYizwBrBhc+U7oJpZ8UmVTdBb0siS6eDmi1QfoB/wZJNZBwD/Sq+XJnvYZ6PxKa0sn5Qys4Jr01n+iRGxfqslZo/yvhX4eUR8VpI+lKxb4LpvVz6bZh/E54BqZsWX41l+SV3Igul1EXFbSfq+ZI913zq+fXrpeLJHoDdahuzx8GX5kN/Mii+/s/wCrgDGRMQ5JenbAb8GdoqIL0sWGQbsLmk+SSsAqwBPNVe+W6hmVmzK9dbTTYC9gRclPZ/SjgPOB+YD7s1iLiMi4pCIGC3pZuBlsq6AwyNienOFO6CaWfHldOtpRDxK+X7Ru1pY5lTg1ErKd0A1s4LzradmZvmpk1tPHVDNrNg8HqqZWV58yG9mlh+Ph2pmlhP3oZqZ5UA+5Dczy49bqGZm+ZADqpnZ3MuegOKAamY29yTU4IBqZpYLt1DNzHLigGpmlhMHVDOzPIjyA+4VkAOqmRWakFuoZmZ5aWjwnVJmZrlwC9XMLA/uQzUzy49bqGZmOfBJKTOzHPnWUzOzPMiH/GZmuXFANTPLiQOqmVkOfFLKzCxP9RFPHVDNrODkW0/NzHLjQ34zs7zURzx1QK03Sy/Ri0tO3IfFF12IGRFcfftjXHrjQ5z8s53Z9rt9+eab6YwdP5HDT76Wzz6fwq7brc+QvbeZufxaKy/F5nv/gZdee7eGWzFvGXr2TTz85Mss0qs7wy7/JQDnX3U3Dzw+Gkks2qs7p/3yxyzeu+fMZV589W32+NkF/HHoXmy72Tq1qnph1EsLtWodE5J+JmmMpOuqVP6Jko6pRtlFNm3aDI4/9zYG7PZ7Bu5/Nj/50WastsL/8OCTr7Dx7qex6Z6n8+bbH3LUfgMBuOXukWw2+Aw2G3wGh/z2Gt5+7xMH03a2y8D1uey0g2ZJO2DXLbjjsqO5/dKj2HzAGlx87b0z502fPoNz/vJPNllvtfauaiFJqniqtWr29B4GfD8iBldxHfOcDz7+jBdeHQ/A519O5bVx77PkYr148MlXmD59BgBPvzSWpZboNduyP9x2PW4d/ky71tdg/bVXomePBWZJ675gt5mvp3z19SzB4Lq/P8r3Nl2bRXt1b7c6Fl1eAVXSspIeTI290ZKOTOmLSLpX0uvp/4VTuiSdL+kNSS9I6t9S+VUJqJL+DKwIDJM0VNKVkp6W9JykQSnPfpLukPQPSWMlHSHpqJRnhKRFUr6D0rKjJN0qaYEy61tJ0t2SnpH0b0mrV2O7imbZJRdh7dWW4ZnR42ZJ32un73Df4y/Pln+X7/Xn1ntGtlPtrDXnXvkvttrzFO584FmG7LstAB9MnMR9j77Ej3f8To1rVyxqUEVTBaYBR0fEGsAA4HBJawLHAvdHxCrA/ek9wPbAKmk6GLikpcKrElAj4hBgArAlsCDwQERskN6fJWnBlLUvsCewIXAq8GVE9AOeAPZJeW6LiA0iYh1gDHBgmVVeBgyJiPWAY4CLm6ubpIMljZQ0MqZNmdtNrZkF5+/KNX/4Cb8551Ymf/HVzPSj99+WadNmcPO/np4l/3prLc+Ur75hzJvvtXdVrRk/P2B7Hrj+BHbcqj/X/f0xAE6/+O8c/ZMd6NSpPi4Tai95tVAj4r2IeDa9nkwWU5YGBgFXp2xXAzun14OAayIzAuglacnmym+Pk1IDgZ1K+ju7Acul1w+mjZosaRLwj5T+IrB2et1X0u+BXkB3YHhp4ZK6AxsDt5R8oPM1V5mIuIwsANOwwOIxF9tVM507NXD1Hw7ilrtHcueDo2am777DRgzctC87H3b+bMv8YOB63DrcrdMi2mGrfhx6/BUM2XdbRr/+Dkefdi0A/530BY88PYZOnTqxzSZ9a1zLGmrb4Ci9JZV+0S9Lf/OzFyv1AfoBTwJLRMR7kAVdSYunbEsD75QsNj6llW2ZtEdAFfDDiHh1lkRpI2BqSdKMkvczSup2FbBzRIyStB+wRZPyG4BPI2LdfKtdXBecMJjXxr3Pxdc/MDNt6++swZH7bMOOPz2PKVO/mSW/JAZt3Y8dfnpue1fVmjFu/Ef0WWYxAB584mVWXDb7+733r0Nn5jnuzBvZfMAa83YwJQ3YX/n5pokRsX6rZWYNsVuBn0fEZy0E7HIzmm2ItUdAHQ4MkTQkIkJSv4h4rg3L9wDek9QFGAzMcoo6fRhjJe0aEbco+2TWjohR5QqrdwPWWZHdd9iI0a+/yyPXZd08p1w0jDOO2ZX5unbm9ouOAGDki+M46owbAdi438pM+PBT3nr345rVe152zKnX8tQLb/LppC/Yco9TOGKfgTzy1CuMHf8hDWpgqSV68bsjf1TrahZYvmfwUyy5FbguIm5LyR9IWjK1TpcEPkzp44FlSxZfhqw7s6z2CKinAOcCL6RgNw7YsQ3Ln0DWJH+LrCugR5k8g4FLJB0PdAFuBDpkQB0x6j8svMERs6Xf+4OTml3msWdfZ+ABf6xmtawFZw/da7a0H26/UavLnfar3atRnbrUkNMA0ykGXQGMiYhzSmYNA/YFzkj//70k/QhJNwIbAZMauwbKqVpAjYg+JW9/Wmb+VWSH87PlL50XEZdQ5sxaRJxY8nossN3c1djMCkltOuRvzSbA3sCLkp5PaceRBdKbJR0IvA3smubdBXwfeAP4Eti/pcJ9p5SZFZrIr4UaEY/S/I2sW5fJH8DhlZbvgGpmhVeAm6Aq4oBqZoVXhNtKK+GAambFlm8falU5oJpZoQl5gGkzs7y4hWpmlhP3oZqZ5cF9qGZm+cju5a+PiOqAamaFVyfx1AHVzIovrzulqs0B1cyKrW3jodaUA6qZFVobx0OtKQdUMyu4YjzRtBIOqGZWeHUSTx1Qzazg5JNSZma58HWoZmY5ckA1M8tJncRTB1QzKz63UM3M8uDBUczM8pENMF0fEdUB1cwKr6FOmqgOqGZWeHUSTx1QzazY1BEGR5G0UEsLRsRn+VfHzGx2ddKF2mILdTQQZDcqNGp8H8ByVayXmdlMdX9SKiKWbc+KmJmVI7Iz/fWgooddS9pd0nHp9TKS1qtutczMvtWgyqZaazWgSroQ2BLYOyV9Cfy5mpUyM5tJ2XiolUy1VslZ/o0jor+k5wAi4hNJXatcLzOzmQoQKytSSUD9RlID2YkoJC0KzKhqrczMEtGxLuy/CLgVWEzSScBuwElVrZWZWYl6Ocvfah9qRFwDHA+cDXwC7BoRN1a7YmZm0Hhhf2VT62XpSkkfSnqpJG1dSSMkPS9ppKQNU7oknS/pDUkvSOrfWvkVneUHOgHfAF+3YRkzs1w0SBVNFbgK2K5J2pnASRGxLvDb9B5ge2CVNB0MXNJqPVvLIGkocAOwFLAMcL2k31RSczOzPKjCqTUR8QjZkfYsyUDjnaE9gQnp9SDgmsiMAHpJWrKl8ivpQ90LWC8ivgSQdCrwDHB6Bcuamc21NlwS1VvSyJL3l0XEZa0s83NguKSzyRqZG6f0pYF3SvKNT2nvNVdQJQH1rSb5OgP/qWA5M7O5lp3lrzj7xIhYv42rOBT4RUTcKmk34ApgG8o3eqOlgloaHOVPaeEvgdGShqf3A4FH21hhM7M5o6oPML0vcGR6fQvwl/R6PFB6C/4yfNsdUFZLLdTGs2CjgX+WpI+ouJpmZjmo8l1QE4DNgYeArYDXU/ow4AhJNwIbAZMiotnDfWh5cJQrcqmqmdlcaOMhf8tlSTcAW5D1tY4HfgccBJwnqTPwFdkZfYC7gO8Db5Adqe/fWvmt9qFKWgk4FVgT6NaYHhGrtmVDzMzmVF4t1IjYo5lZsw34FBEBHN6W8iu5pvQq4P/Ifii2B24GfGG/mbWbvC6bqrZKAuoCETEcICLejIjjyUafMjOrOgk6NaiiqdYquWxqqrL29puSDgHeBRavbrXMzL5VhKH5KlFJQP0F0B34GVlfak/ggGpWysysVJ3E09YDakQ8mV5O5ttBps3M2oWo+D79mmvpwv7baeGugIj4QVVqZGZWqsKRpIqgpRbqhe1WixpZecWluPj6E2tdDWuDJXt1az2TFUbXTvlEwrrvQ42I+9uzImZm5QjoVO8B1cysKApwRVRFHFDNrPA6XECVNF9ETK1mZczMmsoeb1IfEbWSEfs3lPQiaQQWSetIuqDqNTMzSxpU2VRrldx6ej6wI/AxQESMwreemlk7yushfdVWySF/Q0S81aTJPb1K9TEzm4WAzkWIlhWoJKC+kx6rGpI6AUOA16pbLTOzb9VJPK0ooB5Kdti/HPABcF9KMzOrOlX+iOiaq+Re/g+B3duhLmZmZdVJPK1oxP7LKXNPf0QcXCa7mVnuinAGvxKVHPLfV/K6G7ALsz6r2sysagSFGDy6EpUc8t9U+l7SX4F7q1YjM7NSBbnGtBJzcuvpCsDyeVfEzKw5KsQTo1pXSR/qf/m2D7UB+AQ4tpqVMjNrlOdjpKutxYCaniW1DtlzpABmpEermpm1m3oJqC3eepqC5+0RMT1NDqZm1u4kVTTVWiX38j8lqX/Va2JmVkb2GOnKplpr6ZlSnSNiGrApcJCkN4EvyLo0IiIcZM2sXXSEO6WeAvoDO7dTXczMZtNRTkoJICLebKe6mJmVVScN1BYD6mKSjmpuZkScU4X6mJk1IRo6wHWonYDuUCdbYmYdkugYLdT3IuLkdquJmVk5gs510onaah+qmVkt1VMLtaUrt7Zut1qYmbWgIQ0y3drUGklXSvpQ0ktN0odIelXSaElnlqT/RtIbad62rZXfbAs1Ij5ptXZmZu0gxxbqVcCFwDXflq0tgUHA2hExVdLiKX1NssH11wKWAu6TtGpENPtMvQLcW2Bm1jyRBapKptZExCNkAzyVOhQ4IyKmpjwfpvRBwI0RMTUixgJvABu2VL4DqpkVm9p0yN9b0siSqZIni6wKfFfSk5IelrRBSl+aWQfTH5/SmjUn46GambWb7E6pio/5J0bE+m1cRWdgYWAAsAFws6QVKX9ivsUBohxQzazwqnySfzxwWxpN7ylJM4DeKX3ZknzLABNaKsiH/GZWeFJl0xy6A9gqW49WBboCE4FhwO6S5pO0ArAK2RgnzXIL1cwKLr+xTiXdAGxB1tc6HvgdcCVwZbqU6mtg39RaHS3pZuBlYBpweEtn+MEB1cwKrvEsfx4iYo9mZu3VTP5TgVMrLd8B1cwKryOMh2pmVnuiEI83qYQDqpkVWp6H/NXmgGpmhecWqplZTuojnDqgmlnBCejkFqqZWT7qJJ46oJpZ0QnVyUG/A6qZFZ5bqGZmOcgum6qPiOqAambFNncDn7QrB1QzKzzfempmloNsgOla16IyDqhmVng+y29mlpM6OeJ3QK1H5116B08/9xo9F1qQi848HIDr//Ygwx98lp4LLQDAPrttzfr9VuWzyV9yxnk38/qb77L1ZutyyP471LLq86QjTr6W4Y++RO+Fe/DETUMBOOG82xn+75fo0qUTKyzTm4t+uxc9eyzAJ59+zr7HXsFzL7/FHjsO4Kxf7Vbj2hdDvbRQ62UQl7IkbSHpzlrXo71tvdm6nPjr2cfDHbT9AM4//VDOP/1Q1u+3KgBdu3Rm8I+25IDBA9u7mpbsseMA/nb+4bOkbbnR6jx+43E8dsNxrLTc4pxz1T0AzDdfF447ZEdOPnKXWlS1kBr7UCuZaq2uA+q8qu8afejRff6K8nbr1pW1Vl+eLl18MFIrm/RfmYXTkUOjrQasQefOnQDYoO8KTPjgUwAWnH8+vrPuSnTr2qXd61lYFT5CughXAtQ8oErqI+kVSX+R9JKk6yRtI+kxSa9L2jBNj0t6Lv2/WplyFpR0paSnU75BtdieWvrnPU8x5NcXc96ld/D551NqXR2r0LXDnmCbjdesdTUKTRVOtVbzgJqsDJwHrA2sDuwJbAocAxwHvAJsFhH9gN8Cp5UpYyjwQERsAGwJnCVpwaaZJB0saaSkkZM++bgqG1ML239vAy4790jOO/0QFu7VgyuuG17rKlkFzr7ybjp3bmC37TeodVUKKzvkdwu1LcZGxIsRMQMYDdyfnjr4ItAH6Anckp5K+CdgrTJlDASOlfQ88BDQDViuaaaIuCwi1o+I9XsusmhVNqYWFu7ZnU4NDTQ0NLDtVv157c13a10la8UNd47gnkdf4rJT9qubAZRrpV5aqEXpWJta8npGyfsZZHU8BXgwInaR1IcsYDYl4IcR8Wr1qllcn/x3Moss3AOAJ55+heWXWbzGNbKW3Pf4y5x3zX3ceemRLNCta62rU3xFiJYVKEpAbU1PoLHJtV8zeYYDQyQNiYiQ1C8inmuX2rWzsy74Gy+OGcdnk79kvyP+yJ4/3JIXx4xj7FvvI2DxxXpx+IH/OzP/gT/7E19Omcq0adMZ8cwrnHzs3izngNtuDhz6fzz2zOt8/OnnrLXD8Rx78Pf501X3MPXraexy+IUArP//+vCn32RPOF57p98y+Yuv+Oabadz18AvcesHhrL7ikrXchJorwuF8JeoloJ4JXC3pKOCBZvKcApwLvKDs+GkcsGP7VK99/XLIj2ZLG7hl/2bzX3H+L6pZHWvFFafuP1va3oM2bjb/C8NOrmZ16lJ9hNMCBNSIGAf0LXm/XzPzVi1Z7IQ0/yHS4X9ETAF+WsWqmlmt1ElErXlANTNrSXbCqT4iqgOqmRWbx0M1M8tPncRTB1QzKzrVzXW6DqhmVnh1Ek8dUM2s2IpyF1QlHFDNrPjqJKIW5V5+M7NmqcJ/rZaTjUj3YRoXpOm8YySFpN7pvSSdL+kNSS9Iav7umcQB1cwKT6psqsBVwHazl69lge8Bb5ckbw+skqaDgUtaK9wB1cyKrcJgWklAjYhHgE/KzPoT8CsgStIGAddEZgTQS1KLgyo4oJpZ4bXhkL9343jHaTq41bKlnYB3I2JUk1lLA++UvB+f0prlk1JmVmiiTZdNTYyI9SsuW1qAbHD6cg9dK7fWKJM2kwOqmRVeFU/yrwSsAIxKNw8sAzwraUOyFumyJXmXASa0VJgP+c2s+Ko0ZH96UsjiEdEnIvqQBdH+EfE+MAzYJ53tHwBMioj3WirPAdXMCi+vZ0pJugF4AlhN0nhJB7aQ/S7gP8AbwOXAYa2V70N+Myu8vA75I2KPVub3KXkdwOFtKd8B1cyKr07ulHJANbNC8wDTZmZ58QDTZmb5qZN46oBqZkXnAabNzHJTJ/HUAdXMis0DTJuZ5alOIqoDqpkVni+bMjPLiftQzczyIGhwQDUzy0t9RFQHVDMrtDYOMF1TDqhmVnh1Ek8dUM2s+NxCNTPLiW89NTPLSX2EUwdUMys4efg+M7P8+E4pM7O81Ec8dUA1s+Krk3jqgGpmRVfZI6KLwAHVzAqtnu6Uaqh1BczMOgq3UM2s8OqlheqAamaF58umzMzy4Av7zczyUU8npRxQzazwfMhvZpYTt1DNzHJSJ/HUAdXM6kCdRFQHVDMrNEHd3HqqiKh1HWpG0kfAW7WuRxX0BibWuhLWJh11ny0fEYvNTQGS7ib7fCoxMSK2m5v1zY15OqB2VJJGRsT6ta6HVc77rGPwvfxmZjlxQDUzy4kDasd0Wa0rYG3mfdYBuA/VzCwnbqGameXEAdXMLCcOqAUk6WeSxki6rkrlnyjpmGqUbXNP0haS7qx1PaztfKdUMR0GbB8RY2tdETOrnDq2ShcAAATwSURBVFuoBSPpz8CKwDBJQyVdKelpSc9JGpTy7CfpDkn/kDRW0hGSjkp5RkhaJOU7KC07StKtkhYos76VJN0t6RlJ/5a0evtuccckqY+kVyT9RdJLkq6TtI2kxyS9LmnDND2e9tvjklYrU86C5b4DVkwOqAUTEYcAE4AtgQWBByJig/T+LEkLpqx9gT2BDYFTgS8joh/wBLBPynNbRGwQEesAY4ADy6zyMmBIRKwHHANcXJ0tmyetDJwHrA2sTra/NiX7nI8DXgE2S/vtt8BpZcoYSvPfASsYH/IX20Bgp5L+zm7Acun1gxExGZgsaRLwj5T+ItkfMEBfSb8HegHdgeGlhUvqDmwM3KJvB5+YrxobMo8aGxEvAkgaDdwfESHpRaAP0BO4WtIqQABdypTR3HdgTLUrb23ngFpsAn4YEa/OkihtBEwtSZpR8n4G3+7Xq4CdI2KUpP2ALZqU3wB8GhHr5lttS1rbR6eQ/TDuIqkP8FCZMsp+B6yYfMhfbMOBIUrNR0n92rh8D+A9SV2AwU1nRsRnwFhJu6byJWmduayzVa4n8G56vV8zeeb2O2DtyAG12E4hOwx8QdJL6X1bnAA8CdxL1l9XzmDgQEmjgNGAT3q0nzOB0yU9BnRqJs/cfgesHfnWUzOznLiFamaWEwdUM7OcOKCameXEAdXMLCcOqGZmOXFAtWZJmi7p+XQv+i3lxgJoQ1kzR1CStJOkY1vI20vSYXOwjrKjaFUyupakqyT9qA3r6pMuYzKbyQHVWjIlItaNiL7A18AhpTPTjQBt/g5FxLCIOKOFLL3IRtwyqysOqFapfwMrp5bZGEkXA88Cy0oaKOkJSc+mlmx3AEnbpRGXHgV+0FhQGi3rwvR6CUm3pxGxRknaGDgDWCm1js9K+X6ZRlx6QdJJJWUNlfSqpPuA2UZraqqVEbi2SSNuvSZpx5S/k6SzStb907n9IK3jckC1VknqDGxPNvAKZIHrmjRK0hfA8cA2EdEfGAkcJakbcDnwv8B3gf9ppvjzgYfTiFj9ye7WOhZ4M7WOfylpILAK2cha6wLrSdpM0nrA7kA/soC9QQWb09IIXH2AzYEdgD+nbTgQmJRGe9oAOEjSChWsx+ZBHhzFWjK/pOfT638DVwBLAW9FxIiUPgBYE3gs3W7elWwIwdXJRlt6HUDStcDBZdaxFWm4wYiYDkyStHCTPAPT9Fx6350swPYAbo+IL9M6hlWwTS2NwHVzRMwAXpf0n7QNA4G1S/pXe6Z1v1bBumwe44BqLZnSdCSqFDS/KE0C7o2IPZrkW5dsSLo8CDg9Ii5tso6fz8E6rqL5EbialhVp3UMiounQh33auF6bB/iQ3+bWCGATSSsDSFpA0qpkg7GsIGmllG+PZpa/Hzg0LdtJ0kLAZLLWZ6PhwAElfbNLS1oceATYRdL8knqQdS+0pqURuHaV1JDqvCLwalr3oSk/klaVB3i2ZriFanMlIj5KLb0bJDUOTn18RLwm6WDgn5ImAo+SPWWgqSOByyQdCEwHDo2IJ5Q9KuQl4F+pH3UN4InUQv4c2CsinpV0E/A88BZZt0RrGkfgeousT7g0cL8KPAwsARwSEV9J+gtZ3+qzaQi9j4CdK/t0bF7j0abMzHLiQ34zs5w4oJqZ5cQB1cwsJw6oZmY5cUA1M8uJA6qZWU4cUM3McvL/AR3dLbIos5nLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "print(test_labels)\n",
    "data['gender'].unique()\n",
    "\n",
    "gender_names = ['female','male']\n",
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [(\"Confusion matrix, without normalization\", None)]\n",
    "\n",
    "\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(classifier_model, test_feat, test_labels,display_labels = gender_names,\n",
    "                                 cmap=plt.cm.Blues)\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretasi confusion matrix\n",
    "\n",
    "Pada confusion matrix ini menunjukan bahwa terdapat 227 data wanita yang sesuai antara hasil dan prediksinya, dan 121 orang pria yang sesuai dengan hasil prediksinya. Namun, masih terdapat kesalahan pada sebanyak 134 data wanita terprediksi sebagai laki laki dan terdapat 151 data pria yang terprediksi sebagai wanita. Hal ini semakin memperkuat memang akurasi score dari model ini masih cukup rendah yaitu sebesar 0,55 atau 55% yang berarti kurang lebih hanya setengah dari data keseluruhan yang terprediksi benar "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nomor 2. Decision Tree & Random Forest\n",
    "\n",
    "Terdapat perbedaan antara Decision Tree dan Random Forest diantaranya, pada algoritma Decision Tree kita dapat mengontrol dan memilih fitur fitur apa saja yang akan digunakan sebagai predictor dan juga model yang dihasilkan jauh lebih simpel dan biasanya lebih mudah dinterpretasikan karena hasil yang didapatkan jelas perbedaan pengklasifikasiannya sehingga jarang terjadi overlapping juga sedangkan pada algoritma Random Forest, yang sebetulnya merupakan kumpulan dari decision tree yang banyak dan kita dapat mengatur berapa tree yang akan digunakan serta semakin banyak fitur akan semakin tiggi akurasi. Biasanya algoritma Random Forest memilki akurasi yang lebih besar daripada algoritma Decision Tree hal ini karena Random Forest dapat memprediksi dengan akurat fitur yang lebih banyak. Akan tetapi, kita tidak dapat memilih fitur apa yang akan kita gunakan sebagai pengklasifikasian dan tidak bisa mengontrol fitur tersebut diletakan dalam sebuah tree tertentu, Selain itu, random forest pun akurasinya akan terus bertambah selama jumlah pohon yang dibuat akan semakin banyak hingga berada di titik tertentu. \n",
    "\n",
    "\n",
    "Referensi :\n",
    "https://stats.stackexchange.com/questions/285834/difference-between-random-forests-and-decision-tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluasi Model dengan DecisionTree \n",
      "\n",
      "Akurasi =  0.6429699842022117\n",
      "Precision =  0.5864661654135338\n",
      "Recall =  0.5735294117647058\n",
      "F1 =  0.5799256505576207\n",
      "\n",
      " Perbadingan Hasil Prediksi Decision Tree dengan Naive Bayes \n",
      "\n",
      "Akurasi DT =  0.6429699842022117\n",
      "Akurasi NB =   0.5497630331753555 \n",
      "\n",
      "Precision DT =  0.5864661654135338\n",
      "Precision NB =  0.4745098039215686 \n",
      "\n",
      "Recall DT=  0.5735294117647058\n",
      "Recall NB =   0.44485294117647056 \n",
      "\n",
      "F1 score DT =  0.5799256505576207\n",
      "F1 scire NB =  0.45920303605313095 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Mencoba Algoritma Decision Tree\n",
    "\n",
    "#import library\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "#Model Training\n",
    "classifier_tree = DecisionTreeClassifier()\n",
    "classifier_tree.fit(train_feat, train_labels)\n",
    "\n",
    "#predict something\n",
    "y_pred = classifier_tree.predict(test_feat)\n",
    "y_pred\n",
    "\n",
    "#Evaluasi hasil prediksi\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "print(\"Evaluasi Model dengan DecisionTree \\n\")\n",
    "print(\"Akurasi = \", accuracy_score(test_labels, y_pred))\n",
    "print(\"Precision = \", precision_score(test_labels, y_pred))\n",
    "print(\"Recall = \", recall_score(test_labels, y_pred))\n",
    "print(\"F1 = \",f1_score(test_labels, y_pred))\n",
    "\n",
    "print(\"\\n Perbadingan Hasil Prediksi Decision Tree dengan Naive Bayes \\n\")\n",
    "print(\"Akurasi DT = \", accuracy_score(test_labels, y_pred))\n",
    "print(\"Akurasi NB =  \", accuracy_score(test_labels, pred), \"\\n\")\n",
    "print(\"Precision DT = \", precision_score(test_labels, y_pred))\n",
    "print(\"Precision NB = \", precision_score(test_labels, pred) ,\"\\n\")\n",
    "print(\"Recall DT= \", recall_score(test_labels, y_pred))\n",
    "print(\"Recall NB =  \", recall_score(test_labels, pred),\"\\n\")\n",
    "print(\"F1 score DT = \",f1_score(test_labels, y_pred))\n",
    "print(\"F1 scire NB = \",f1_score(test_labels, pred),\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kesimpulan\n",
    "Dilihat dari perbandingan tersebut Algoritma Decision Tree menghasilkan hasil prediksi dengan akurasi, precision, recall, dan F1 Score yang lebih baik daripada algoritma Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A31j8hR_G-aO"
   },
   "source": [
    "# B. Klasifikasi Emosi pada Tweet Bahasa \n",
    "\n",
    "Pada tutorial ini, kita akan mengklasifikan <i>tweet</i> Bahasa Indonesia ke dalam lima kelas emosi yaitu senang, cinta, marah, sedih, dan takut. <i>Dataset</i> yang digunakan dalam percobaan ini didapatkan dari <i>paper</i> berikut:\n",
    "\n",
    "Mei Silvana Saputri, Rahmad Mahendra, and Mirna Adriani, <i>Emotion Classification on Indonesian Twitter Dataset</i>.  International Conference on Asian Language Processing (IALP) 2018. Bandung. 2018. \n",
    "\n",
    "<i>Dataset</i> terdiri dari 4.403 <i>tweet</i> yang sudah dilakukan <i>pre-processing</i> dengan ketentuan sebagai berikut:\n",
    "* <i>Username</i> dan <i>mention</i> (ditandai dengan @) diganti dengan kata [USERNAME]\n",
    "* URL/<i>hyperlink</i> (http:// atau https://..) diganti dengan kata [URL]\n",
    "* Nomor sensitif, misalnya nomor telepon, nomor <i>invoice</i>, dan nomor pelacakan jasa pengiriman diganti dengan kata [SENSITIVE-NO]\n",
    "\n",
    "<i>Dataset</i> ini memuat <i>tweet</i> beremosi eksplisit dan implisit. Tabel 2 menunjukkan contoh <i>tweet</i> beremosi eksplisit dan implisit.\n",
    "\n",
    "Tabel 2. Contoh Data Emosi Eksplisit dan Emosi Implisit\n",
    "\n",
    "| Emosi Eksplisit | Emosi Implisit |\n",
    "|------|------|\n",
    "|hari ini libur, rencananya mau nonton Jurassic World, tapi kayanya gajadi deh mengingat kondisi yg gak fit bgt ini <b>sebel</b>. Rusak rencana sebelanga.. <b>sebel</b> akutu <font color='blue'>(marah)</font>|Ini aja membuktikan anda sudah TIDAK BENAR....!!! MASA NAPI KORUPTOR BISA PUNYA HP DI PENJARA ITU SDH MELANGGAR ATURAN.... DAN ANDA DG ENAKNYA MELANGGAR ATURAN...!! INI MENANDAKAN BAHWA ITULAH KARAKTER ANDA <font color='blue'>(marah)</font>|\n",
    "\n",
    "Untuk mengklasifikan <i>tweet</i> menjadi lima kelas emosi, dilakukan ekstraksi 4 fitur berikut:\n",
    "* Fitur Unigram\n",
    "* Fitur Leksikon Sentimen \n",
    "* Fitur POS Tag\n",
    "* Fitur Ortografi\n",
    "\n",
    "Langkah-langkah untuk melakukan klasifikasi emosi pada <i>dataset tweet</i> emosi tersebut adalah sebagai berikut:\n",
    "\n",
    "<b>1. Import library</b><br>\n",
    "<i>Library</i> yang digunakan pada tutorial ini antara lain pandas, numpy, nltk, Sastrawi, dan sklearn. \n",
    "\n",
    "<b>#Code 1</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T16:04:51.816914Z",
     "start_time": "2021-05-31T16:04:44.188892Z"
    },
    "id": "j4UnhombG-aO",
    "outputId": "ae469e36-6c0e-4d2b-e072-29aff7118a25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\asus\\anaconda3\\lib\\site-packages (3.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from nltk) (1.12.0)\n",
      "Requirement already satisfied: Sastrawi in c:\\users\\asus\\anaconda3\\lib\\site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install Sastrawi\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import Sastrawi\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.tag import CRFTagger\n",
    "from collections import Counter\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "_dPMwe7VTglL"
   },
   "source": [
    "<b>2. Membaca data</b><br>\n",
    "Data dibaca dengan <i>library</i> pandas.\n",
    "\n",
    "<b>#Code 2</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T16:13:11.250468Z",
     "start_time": "2021-05-31T16:13:11.225375Z"
    },
    "id": "-WRNfhrMG-aR",
    "outputId": "2d79f29b-b917-4d0a-e012-adbefb5472d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4401\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>anger</td>\n",
       "      <td>Soal jln Jatibaru,polisi tdk bs GERTAK gubernu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>anger</td>\n",
       "      <td>Sesama cewe lho (kayaknya), harusnya bisa lebi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>happy</td>\n",
       "      <td>Kepingin gudeg mbarek Bu hj. Amad Foto dari go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "      <td>Jln Jatibaru,bagian dari wilayah Tn Abang.Peng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>happy</td>\n",
       "      <td>Sharing pengalaman aja, kemarin jam 18.00 bata...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              tweet\n",
       "0  anger  Soal jln Jatibaru,polisi tdk bs GERTAK gubernu...\n",
       "1  anger  Sesama cewe lho (kayaknya), harusnya bisa lebi...\n",
       "2  happy  Kepingin gudeg mbarek Bu hj. Amad Foto dari go...\n",
       "3  anger  Jln Jatibaru,bagian dari wilayah Tn Abang.Peng...\n",
       "4  happy  Sharing pengalaman aja, kemarin jam 18.00 bata..."
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# membaca data\n",
    "raw_data = pd.read_csv(\"dataset/Twitter_Emotion_Dataset.csv\",\n",
    "                       delimiter=\",\", encoding=\"Latin-1\")\n",
    "print(raw_data.shape[0])\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNy4YqvpTglM"
   },
   "source": [
    "<b>3. Pra-pemrosesan data</b><br>\n",
    "Data Twitter bersifat <i>unstructured</i> dan memiliki format penulisan bebas (tidak sesuai kaidah penulisan yang benar). Oleh karena itu, dilakukan pra-pemrosesan data untuk melakukan normalisasi isi <i>tweet</i>. \n",
    "\n",
    "Dalam percobaan ini, dilakukan pra-pemrosesan berupa:\n",
    "\n",
    "    a. Normalisasi tweet\n",
    "    Normalisasi tweet terdiri dari pengubahan ke huruf kecil, pembuangan spasi yang berlebihan, trimming, pembuangan tanda baca, penghilangan huruf berulang (misalnya haiiii -> hai). Fungsi normalisasi (tweet) menerima input berupa satu buah tweet mentah bertipe string. \n",
    "\n",
    "<b>#Code 3a</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T16:13:14.277808Z",
     "start_time": "2021-05-31T16:13:14.270222Z"
    },
    "id": "RN0c_EEOG-aT"
   },
   "outputs": [],
   "source": [
    "def normalisasi(tweet):\n",
    "    normal_tw = tweet.lower()  # lowercase\n",
    "    normal_tw = re.sub('\\s+', ' ', normal_tw)  # remove extra space\n",
    "    normal_tw = normal_tw.strip()  # trim depan belakang\n",
    "    normal_tw = re.sub(r'[^\\w\\s]', '', normal_tw)  # buang punctuation\n",
    "    # regex huruf yang berulang kaya haiiii (untuk fitur unigram)\n",
    "    normal_regex = re.compile(r\"(.)\\1{1,}\")\n",
    "    # buang huruf yang berulang\n",
    "    normal_tw = normal_regex.sub(r\"\\1\\1\", normal_tw)\n",
    "    return normal_tw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T16:39:44.285857Z",
     "start_time": "2020-04-27T16:39:44.271983Z"
    },
    "editable": false,
    "id": "osigHNdFTglM"
   },
   "source": [
    "    b. Pembuangan stopwords dan istilah spesial (username, hyperlink, sensitive-no)\n",
    "    Daftar stopwords didapatkan dari penelitian Tala.\n",
    "    \n",
    "    Tala, F. Z. (2003). A Study of Stemming Effects on Information Retrieval in Bahasa Indonesia. M.S. thesis. M.Sc. Thesis. Master of Logic Project. Institute for Logic, Language and Computation. Universiteti van Amsterdam The Netherlands.\n",
    "    \n",
    "    Fungsi remove_stopwords(tweet) menerima masukan berupa tweet yang sudah dinormalisasi yang bertipe string.\n",
    "    \n",
    "<b># Code 3b</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T16:13:16.262474Z",
     "start_time": "2021-05-31T16:13:16.257932Z"
    },
    "id": "M0VfpR9WG-aW"
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(tweet):\n",
    "    token = nltk.word_tokenize(tweet)\n",
    "    token_afterremoval = []\n",
    "    for k in token:\n",
    "        if k not in stopwords and k not in special_list:\n",
    "            token_afterremoval.append(k)\n",
    "\n",
    "    str_clean = ' '.join(token_afterremoval)\n",
    "    return str_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T16:43:16.134661Z",
     "start_time": "2020-04-27T16:43:16.130355Z"
    },
    "editable": false,
    "id": "ZTH3VFDjTglN"
   },
   "source": [
    "    c. Di luar tutorial ini Anda bisa mencoba opsi stemming pada tahap pra-pemrosesan. Fungsi stemming akan didefinisikan pada tutorial ini, namun tidak dijalankan untuk mempercepat proses normalisasi isi tweet. Pra-pemrosesan sifatnya tidak wajib seluruhnya diterapkan. Fungsi stemming(tweet) menerima masukan berupa satu buah tweet bertipe string. \n",
    "\n",
    "<b>#Code 3c</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T16:13:18.000118Z",
     "start_time": "2021-05-31T16:13:17.987225Z"
    },
    "id": "fsQCAy0RG-aZ"
   },
   "outputs": [],
   "source": [
    "def stemming(tweet):\n",
    "    token = nltk.word_tokenize(tweet)\n",
    "    stem_kalimat = []\n",
    "    for k in token:\n",
    "        stem_kata = stemmer.stem(k)\n",
    "        stem_kalimat.append(stem_kata)\n",
    "\n",
    "    stem_kalimat_str = ' '.join(stem_kalimat)\n",
    "    return stem_kalimat_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "p5gDoz5eTglN"
   },
   "source": [
    "    d. Pra-pemrosesan tweet secara keseluruhan\n",
    "    Pada tahap ini, akan dilakukan pemanggilan fungsi normalisasi dan remove_stopwords yang sudah didefinisikan sebelumnya. Setelah itu akan ditampilkan sampel tiga tweet pertama yang sudah dilakukan pra-pemrosesan. \n",
    "    \n",
    "<b>#Code 3d</b>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T16:13:58.131269Z",
     "start_time": "2021-05-31T16:13:55.594345Z"
    },
    "id": "4f4UGYY9G-ac",
    "outputId": "acef8644-0421-41a7-bc6b-262af89953f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['jln jatibarupolisi tdk bs gertak gubernur emangny polisi tdk pmbhasan jgn berpolitik pengaturan wilayahhak gubernur tn abang turun temurunpelikperlu kesabaran',\n",
       " 'cewe lho kayaknya rasain sibuk jaga rasain sakitnya haid paniknya pulang malem gimana orang asing wajarlah korban takut curhat dibela dihujat',\n",
       " 'kepingin gudeg mbarek bu hj amad foto google sengaja biar temanteman jg membayangkannya berbagi indah']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "def pra_pemrosesan(list_tweet):\n",
    "    tweet_clean = []\n",
    "    for tw in list_tweet:\n",
    "        normal_tweet = normalisasi(tw)\n",
    "#         normal_tweet = stemming(normal_tweet)\n",
    "        normal_tweet = remove_stopwords(normal_tweet)\n",
    "        tweet_clean.append(normal_tweet)\n",
    "    return tweet_clean\n",
    "\n",
    "raw_tweet = raw_data['tweet'].tolist()\n",
    "label = raw_data['label'].tolist()\n",
    "\n",
    "stopwords = pd.read_csv('dataset/stopwords.csv', header=None)[0].values\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "special_list = ['username', 'url', 'sensitive-no']\n",
    "clean_tweet = pra_pemrosesan(raw_tweet)\n",
    "clean_tweet[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9H6mo8cfTglO"
   },
   "source": [
    "<b>4. Ekstraksi Fitur Unigram</b><br>\n",
    "Fitur <i>unigram</i> memuat informasi mengenai frekuensi kemunculan suatu kata di dokumen. Fitur <i>unigram</i> dibentuk menggunakan <i>library</i> $CountVectorizer$ dari $Scikit-learn$. Jumlah kata unik (<i>vocabulary</i>) yang terbentuk bergantung dari data yang digunakan. Tapi, dalam percobaan ini akan digunakan parameter max_features=2000 dimana akan diambil 2000 kata unik yang memiliki frekuensi kemunculan tertinggi. \n",
    "\n",
    "<b>#Code 4</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T16:23:15.379984Z",
     "start_time": "2021-05-31T16:23:15.198961Z"
    },
    "id": "CU0frcVPG-af",
    "outputId": "a5c5076d-8402-428f-dcc1-6109be2b35d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "['10', '100', '11', '12', '15', '20', '2016', '2017', '2018', '2019']\n"
     ]
    }
   ],
   "source": [
    "def ekstraksi_unigram(tweet):\n",
    "    unigram = CountVectorizer(ngram_range=(1, 1), max_features=2000)\n",
    "    unigram_matrix = unigram.fit_transform(np.array(tweet)).todense()\n",
    "    nama_fitur = unigram.get_feature_names()\n",
    "    return unigram_matrix, nama_fitur\n",
    "\n",
    "\n",
    "unigram_feat, feat_name = ekstraksi_unigram(clean_tweet)\n",
    "print(unigram_feat[:3])\n",
    "print(feat_name[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYCLN0FxTglO"
   },
   "source": [
    "<b>5. Ekstraksi Fitur Leksikon Sentimen (Kamus Sentimen)</b><br>\n",
    "Orientasi sentimen dapat digunakan sebagai fitur untuk klasifikasi. Pada tutorial ini, akan digunakan leksikon sentimen dari penelitian berikut ini:\n",
    "\n",
    "Clara Vania, Moh. Ibrahim, and Mirna Adriani. Sentiment Lexicon Generation for an Under-Resourced Language. CICLING 2014 (IJCLA)\n",
    "\n",
    "Daftar kata bersentimen positif terdapat pada <i>positif_vania.txt</i> dan daftar kata bersentimen negatif terdapat pada <i>negatif_vania.txt</i>. \n",
    "\n",
    "<b>#Code 5a</b><br>\n",
    "<i>Code</i> ini digunakan untuk mendefinisikan fungsi $ekstraksi\\_sentimen$ yang menerima input berupa daftar <i>tweet</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T16:24:28.127304Z",
     "start_time": "2021-05-31T16:24:28.104434Z"
    },
    "id": "8_TRwqq_G-ah"
   },
   "outputs": [],
   "source": [
    "def ekstraksi_sentimen(list_tweet):\n",
    "    pos = pd.read_csv(\"dataset/positif_vania.txt\", header=None, names=['pos'])\n",
    "    list_pos = pos['pos'].tolist()\n",
    "    neg = pd.read_csv(\"dataset/negatif_vania.txt\", header=None, names=['neg'])\n",
    "    list_neg = neg['neg'].tolist()\n",
    "\n",
    "    fitur_sentimen_all = []\n",
    "    for tweet in list_tweet:\n",
    "        # inisiasi value\n",
    "        emosi = [\"positif\", \"negatif\"]\n",
    "        value = [0, 0]\n",
    "        emosi_value = {}\n",
    "        for i in range(len(emosi)):\n",
    "            emosi_value[emosi[i]] = value[i]\n",
    "\n",
    "        list_kata = tweet.split()\n",
    "        for k in list_kata:\n",
    "            if k in list_pos:\n",
    "                emosi_value[\"positif\"] += 1\n",
    "            if k in list_neg:\n",
    "                emosi_value[\"negatif\"] += 1\n",
    "\n",
    "        fitur_sentimen_perkalimat = list(emosi_value.values())\n",
    "        fitur_sentimen_all.append(fitur_sentimen_perkalimat)\n",
    "\n",
    "    return fitur_sentimen_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x97Es3FnTglP"
   },
   "source": [
    "<b>#Code 5b</b><br>\n",
    "Pemanggilan fungsi $ekstraksi\\_sentimen$ dan menampilkan sampel hasil ekstraksi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T16:24:30.104613Z",
     "start_time": "2021-05-31T16:24:29.258881Z"
    },
    "id": "Z6kePED1G-ak",
    "outputId": "a43db875-eef8-45ff-b914-6cdfdb293232"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0], [0, 2], [1, 0], [0, 0], [1, 0], [0, 2], [0, 0], [0, 0], [0, 1], [0, 0]]\n"
     ]
    }
   ],
   "source": [
    "sentlex_feat = ekstraksi_sentimen(clean_tweet)\n",
    "print(sentlex_feat[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pumZs6hsTglP"
   },
   "source": [
    "<b>6. Ekstraksi Fitur Part-Of-Speech Tag</b><br>\n",
    "<i>Part-of-speech</i> (POS) merupakan kelas kata yang dapat digunakan untuk mengenali emosi pada <i>tweet</i>. Pada percobaan ini, akan dihitung kemunculan kata sifat (JJ) dan kata negasi (NEG) berdasarkan <i>pre-trained</i> POS Tag dari penelitian Dinakarami et. al. yang sudah dikonversi ke dalam bentuk CRF Tagger agar bisa dibaca dari NLTK. \n",
    "\n",
    "Arawinda Dinakaramani, Fam Rashel, Andry Luthfi, and Ruli Manurung. <i>Designing an Indonesian Part of speech Tagset and Manually Tagged Indonesian Corpus</i>. International Conference on Asian Language Processing (IALP 2014). Kuching, 20-22 October 2014.\n",
    "\n",
    "<i>Raw data pre-trained</i> POS Tag yang belum ditransformasi ke dalam bentuk CRF Tagger bisa didapatkan di Fam Rashel’s <a href='https://github.com/famrashel/idn-tagged-corpus'>Github</a>. \n",
    "\n",
    "<b>#Code 6a</b><br>\n",
    "Mendefinisikan fungsi $ekstraksi\\_pos$ yang menerima masukan berupa daftar <i>tweet</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T16:25:15.679431Z",
     "start_time": "2021-05-31T16:25:15.665504Z"
    },
    "id": "oCI1qDZkG-am"
   },
   "outputs": [],
   "source": [
    "def ekstraksi_pos(list_tweet):\n",
    "    ct = CRFTagger()\n",
    "    ct.set_model_file(\"dataset/all_indo_man_tag_corpus_model.crf.tagger\")\n",
    "    pos_feat_list = []\n",
    "    count_tag = []\n",
    "    for tweet in list_tweet:\n",
    "        token = nltk.word_tokenize(tweet)\n",
    "        tag = ct.tag_sents([token])\n",
    "        flat_tag = [item for sublist in tag for item in sublist]\n",
    "        pos_count = Counter([j for i, j in flat_tag])\n",
    "        pos_feat = (pos_count['JJ'], pos_count['NEG'])\n",
    "        pos_feat_list.append(pos_feat)\n",
    "    return pos_feat_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJ9nak3jTglQ"
   },
   "source": [
    "<b>#Code 6b</b><br>\n",
    "Memanggil fungsi $ekstraksi\\_pos$ dan menampilkan sampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T16:25:17.461624Z",
     "start_time": "2021-05-31T16:25:16.359868Z"
    },
    "id": "gzc7yD5SG-as",
    "outputId": "d7b647e0-791f-4d1a-da41-4338f4667e5a"
   },
   "outputs": [],
   "source": [
    "import pycrfsuite\n",
    "postag_feat = ekstraksi_pos(raw_tweet) #ganti raw tweet supaya kata tidak dan bukannya gak ilang\n",
    "print(postag_feat[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T17:08:56.890723Z",
     "start_time": "2020-04-27T17:08:56.878954Z"
    },
    "id": "JKJE4cqKTglQ"
   },
   "source": [
    "<b>7. Ekstraksi Fitur Ortografi</b><br>\n",
    "Pada percobaan ini, fitur ortografi yang digunakan sebagai fitur untuk mengenali emosi pada <i>tweet</i> yaitu jumlah huruf kapital, jumlah tanda seru, jumlah huruf dan panjang karakter. Oleh karena itu, <i>dataset</i> yang digunakan untuk menghasilkan fitur ortografi merupakan dataset awal yang belum mengalami pra-pemrosesan. \n",
    "\n",
    "<b>#Code 7a</b><br>\n",
    "Mendefinisikan fungsi $ekstraksi\\_ortografi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T16:25:52.670975Z",
     "start_time": "2021-05-31T16:25:52.665035Z"
    },
    "id": "9n2_66w3G-aw"
   },
   "outputs": [],
   "source": [
    "def ekstraksi_ortografi(raw_tweet):\n",
    "    all_orto_feat = []\n",
    "    for tw in raw_tweet:\n",
    "        capital_count = sum(1 for c in tw if c.isupper())\n",
    "        exclamation_count = sum((1 for c in tw if c == \"!\"))\n",
    "        word_len = len(nltk.word_tokenize(tw))\n",
    "        char_len = len(tw)\n",
    "        orto_feat = [capital_count, exclamation_count, word_len, char_len]\n",
    "        all_orto_feat.append(orto_feat)\n",
    "    return all_orto_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tRTdiLIyTglR"
   },
   "source": [
    "<b>#Code 7b</b><br>\n",
    "Memanggil fungsi EkstraksiPOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T16:25:54.474931Z",
     "start_time": "2021-05-31T16:25:53.329558Z"
    },
    "id": "AFxydYvsG-az",
    "outputId": "7f2352dc-37c7-4cee-ce7f-3536e68fc623"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[35, 0, 41, 220], [3, 0, 44, 235], [5, 0, 22, 116]]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orto_feat = ekstraksi_ortografi(raw_tweet)\n",
    "orto_feat[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "G62htyZDTglR"
   },
   "source": [
    "<b>8. Klasifikasi</b><br>\n",
    "Pada percobaan ini, klasifikasi dilakukan dengan menggunakan algoritma Multinomial Naïve Bayes. Pembagian data training dan testing digunakan menggunakan model k-fold Cross Validation dengan nilai $k = 10$. Dengan model Cross-Validation, proses training dan testing akan dilakukan sebanyak $k$ kali dengan pembagian data yang berbeda. \n",
    "\n",
    "<b>#Code 8</b><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T16:26:01.118719Z",
     "start_time": "2021-05-31T16:25:58.641247Z"
    },
    "id": "YdcnTcRtG-a1",
    "outputId": "b25989db-ea4d-4406-dbcb-4e3362b4e70f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'postag_feat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-23045c3c120b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeat_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0munigram_feat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentlex_feat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpostag_feat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morto_feat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfeat_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"Unigram\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Sentimen\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"POS\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Ortografi\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeat_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'postag_feat' is not defined"
     ]
    }
   ],
   "source": [
    "feat_list = [unigram_feat, sentlex_feat orto_feat]\n",
    "feat_name = [\"Unigram\", \"Sentimen\", \"POS\", \"Ortografi\"]\n",
    "for f, n in zip(feat_list, feat_name):\n",
    "    X = f\n",
    "    y = label\n",
    "    scoring = ['accuracy', 'f1_macro']\n",
    "    nb = MultinomialNB()\n",
    "    scores = cross_validate(nb, X, y, cv=10, scoring=scoring)\n",
    "    acc = np.mean(scores['test_accuracy'])\n",
    "    f1 = np.mean(scores['test_f1_macro'])\n",
    "    print(\"Jenis Fitur : \", n)\n",
    "    print(\"Akurasi :\", acc)\n",
    "    print(\"F1-Score :\", f1)\n",
    "    print(\"---------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HoyQgVrOTglS"
   },
   "source": [
    "<b><font color='red'>Tugas Tutorial B</font></b>\n",
    "1. Menurut pemahaman Anda, apa yang dimaksud dengan fitur leksikon? Temukan leksikon lainnya yang dapat digunakan untuk mengekstraksi fitur leksikon.\n",
    "\n",
    "2. Lakukan eksperimen dengan menggunakan fitur unigram + bigram dengan mengubah <b>#Code 4</b>. Apakah fitur tersebut lebih baik dibandingkan fitur unigram saja berdasarkan F1-score? \n",
    "\n",
    "3. Kombinasikan 4 fitur yang sudah kita ekstraksi sebelumnya (unigram, sentimen leksikon, POS Tag dan ortografi). Gunakan F1-Score sebagai metrik evaluasi dan jumlah <i>fold</i> <i>cross validation</i>:\n",
    "    * k = 3 jika nama lengkap Anda dimulai huruf A-H\n",
    "    * k = 4 jika nama lengkap Anda dimulai huruf I-M\n",
    "    * k = 5 jika nama lengkap Anda dimulai huruf N-Z\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Tampilkan hasil percobaan pada tabel, sebagai contoh:\n",
    "\n",
    "|Kombinasi Fitur|F1-Score|\n",
    "|------|------|\n",
    "|unigram|------|\n",
    "|POS tag|------|\n",
    "|sentimen leksikon|------|\n",
    "|ortografi|------|\n",
    "|[unigram, POS tag]|------|\n",
    "|[unigram, sentimen leksikon]|------|\n",
    "|[unigram, ortografi]|------|\n",
    "|...|...|\n",
    "|[unigram, POS tag, sentimen leksikon, ortografi]|------|\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Lakukan analisis dari hasil yang Anda dapat (hint: gunakan np.hstack untuk menggabungkan dua fitur atau lebih).\n",
    "\n",
    "4. [BONUS] Gunakan leksikon yang Anda dapat pada soal no 1 untuk mengekstraksi fitur sentimen leksikon lainnya. Apakah fitur tersebut lebih baik daripada fitur leksikon dari penelitian Vania berdasarkan F1-score? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWERVqXOTglS"
   },
   "source": [
    "1. Leksikon secara bahasa berarti kamus, maka fitur leksikon ini adalah fitur yang digunakan untuk menyeleksi kata kata yang berada kamus tersebut agar tidak terdapat pada data tweet yang kita punya, leksikon dapat bermacama macam diantaranya bahasa gaul, bahasa kasar, ataupun kata kata singkatan yang ada. Salah satu contoh leksikon yang saya dapatkan adalah lexicon yang diapakai di bahasa bahasa blog pribadi seperti microblog\n",
    "\n",
    "    https://github.com/fajri91/InSet\n",
    "\n",
    "    https://www.researchgate.net/publication/321757985_InSet_Lexicon_Evaluation_of_a_Word_List_for_Indonesian_Sentiment_Analysis_in_Microblogs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "colab": {
   "collapsed_sections": [],
   "name": "Tutorial2_TextClassification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
